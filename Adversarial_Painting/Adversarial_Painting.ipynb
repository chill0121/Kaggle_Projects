{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Painting Style Using Generative Adversarial Networks (GANs)\n",
    "\n",
    "---\n",
    "\n",
    "This project derives from the Kaggle competition with the name Gan Getting Started (I'm Something of a Painter Myself), found here: https://www.kaggle.com/competitions/gan-getting-started/overview\n",
    "\n",
    "You can find this project at the github repo: https://github.com/chill0121/Kaggle_Projects/tree/main/Adversarial_Painting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "- 1.[**Data Source Information**](#datasource)\n",
    "  - 1.1. [Dataset Information](#data)\n",
    "  - 1.2. [Kaggle Information](#kaggle)\n",
    "- 2.[**Setup**](#setup)\n",
    "  - 2.1. [Environment Details for Reproducility](#env)\n",
    "  - 2.2. [Importing the Data](#dataimport)\n",
    "- 3.[**Data Preprocessing**](#datapre)\n",
    "  - 3.1. [First Looks](#firstlook)\n",
    "  - 3.2. [Pixel Normalization](#norm)\n",
    "- 4.[**Exploratory Data Analysis (EDA)**](#eda)\n",
    "- 5.[**Models**](#models)\n",
    "  - 5.1. [Model Helper Functions](#helper)\n",
    "  - 5.2. [Generative Adversarial Network (GAN)](#gan)\n",
    "- 6.[**Results**](#results)\n",
    "- 7.[**Conclusion - Kaggle Submission Test Set**](#conclusion)\n",
    "  - 7.1. [Possible Areas for Improvement](#improvements)\n",
    "\n",
    "- [**Appendix A - Online References**](#appendixa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Source Information <a name=\"datasource\"></a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data Information: <a name=\"data\"></a>\n",
    "\n",
    "Color images (256 x 256 pixels) extracted from histopathologic scans of lymph node sections. These 96 x 96 images are patches of a whole slide image.\n",
    "\n",
    "- The monet directories contain Monet paintings used to train the model.\n",
    "- The photo directories contain photos used to add the Monet-style to them for submission.\n",
    "\n",
    "**Data Info:**\n",
    "- 300 Monet Painting Images\n",
    "    - 256 x 256 x 3\n",
    "- 7028 Photos\n",
    "    - 256 x 256 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Kaggle Information: <a name=\"kaggle\"></a>\n",
    "\n",
    "#### Description:\n",
    "\n",
    "We recognize the works of artists through their unique style, such as color choices or brush strokes. The “je ne sais quoi” of artists like Claude Monet can now be imitated with algorithms thanks to generative adversarial networks (GANs). In this getting started competition, you will bring that style to your photos or recreate the style from scratch!\n",
    "\n",
    "Computer vision has advanced tremendously in recent years and GANs are now capable of mimicking objects in a very convincing way. But creating museum-worthy masterpieces is thought of to be, well, more art than science. So can (data) science, in the form of GANs, trick classifiers into believing you’ve created a true Monet? That’s the challenge you’ll take on!\n",
    "\n",
    "The Challenge:\n",
    "A GAN consists of at least two neural networks: a generator model and a discriminator model. The generator is a neural network that creates the images. For our competition, you should generate images in the style of Monet. This generator is trained using a discriminator.\n",
    "\n",
    "The two models will work against each other, with the generator trying to trick the discriminator, and the discriminator trying to accurately classify the real vs. generated images.\n",
    "\n",
    "Your task is to build a GAN that generates 7,000 to 10,000 Monet-style images.\n",
    "\n",
    "#### Evaluation:\n",
    "\n",
    "MiFID\n",
    "Submissions are evaluated on MiFID (Memorization-informed Fréchet Inception Distance), which is a modification from Fréchet Inception Distance (FID).\n",
    "\n",
    "The smaller MiFID is, the better your generated images are.\n",
    "\n",
    "What is FID?\n",
    "Originally published here ([github](https://arxiv.org/abs/1706.08500)), FID, along with Inception Score (IS), are both commonly used in recent publications as the standard for evaluation methods of GANs.\n",
    "\n",
    "#### Citation: \n",
    "\n",
    "Amy Jang, Ana Sofia Uzsoy, Phil Culliton. (2020). I’m Something of a Painter Myself. Kaggle. https://kaggle.com/competitions/gan-getting-started\n",
    "\n",
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup <a name=\"setup\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score,classification_report, confusion_matrix, ConfusionMatrixDisplay, auc, roc_curve, RocCurveDisplay, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Environment Information for Reproducibility: <a name=\"env\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.9 (main, Apr  2 2024, 08:25:04) [Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "<module 'pandas'  using version: 2.1.4\n",
      "<module 'numpy'  using version: 1.26.4\n",
      "<module 'seaborn'  using version: 0.13.2\n",
      "<module 'sklearn'  using version: 1.3.2\n",
      "<module 'tensorflow'  using version: 2.16.2\n",
      "<module 'torch'  using version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "packages = [pd, np, sns, sklearn, tf, torch]\n",
    "for package in packages:\n",
    "    print(f\"{str(package).partition('from')[0]} using version: {package.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Importing the Data: <a name=\"dataimport\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "current_wdir = os.getcwd()\n",
    "data_folder = current_wdir + '/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing <a name=\"datapre\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. First Looks: <a name=\"firstlook\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Pixel Normalization: <a name=\"norm\"></a>\n",
    "\n",
    "The models will perform better and more efficiently if we normalize the pixel values to range from 0-1 instead of 0-255 as it is now.\n",
    "\n",
    "A function to perform this as needed will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(array):\n",
    "    return array / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten and stack (using reshape) array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_stack(X_array):\n",
    "    return X_array.flatten().reshape(len(X_array), 96*96*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA) <a name=\"eda\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models <a name=\"models\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Model Helper Functions <a name=\"helper\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Generative Adversarial Network (GAN) <a name=\"gan\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results <a name=\"results\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the best model's test results green at each proportion.\n",
    "def max_value_highlight(df):\n",
    "    max_test_rows = df.max()\n",
    "    is_max = (df == max_test_rows)\n",
    "    \n",
    "    return ['background-color:green' if v else '' for v in is_max]\n",
    "\n",
    "# Highlight the top two results in each column blue so that 2nd place is in blue after .apply().\n",
    "def highlight_top_two(df):\n",
    "    # Sort values\n",
    "    test_rows = df\n",
    "    sorted_df = test_rows.sort_values(ascending = False)\n",
    "    top_two = sorted_df.iloc[: 2]\n",
    "    # Mask\n",
    "    is_top_two = df.isin(top_two)\n",
    "\n",
    "    return ['background-color: blue' if v else '' for v in is_top_two]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the test set the .csv files must be submitted to Kaggle. Each model's predictions were saved above and manually submitted. Below you can find a screenshot of all the results.\n",
    "\n",
    "<img src=\"https://github.com/chill0121/Kaggle_Projects/blob/main/Cancer_Detection_Histopathology/Models/Kaggle_Submission_Scores.png?raw=true\" alt=\"results\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion - Kaggle Submission Test Set <a name=\"conclusion\"></a>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Possible Areas for Improvement <a name=\"improvements\"></a>\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A - Online References: <a name=\"appendixa\"></a>\n",
    "\n",
    "Resources that helped along the way in no particular order.\n",
    "\n",
    " Exported to HTML via command line using:\n",
    "\n",
    "- `jupyter nbconvert Adversarial_Painting.ipynb --to html`\n",
    "- `jupyter nbconvert Adversarial_Painting.ipynb --to html --HTMLExporter.theme=dark`\n",
    "\n",
    "###### [Back to Table of Contents](#toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
